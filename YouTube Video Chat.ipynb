{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYqZnX3kSaWEJOv8tXW+wk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdessamed122/1-st-projet-with-API/blob/main/YouTube%20Video%20Chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WFK98Rb_ip1",
        "outputId": "6a595f88-eaa7-4e9d-d77a-88db227e598e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.22.0)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: yt_dlp in /usr/local/lib/python3.11/dist-packages (2025.3.31)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.49)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.22)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed faiss-cpu-1.10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install groq pytube youtube-transcript-api\n",
        "!pip install yt_dlp\n",
        "!pip install langchain faiss-cpu sentence-transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYmW7mF9I10B",
        "outputId": "6bfaa492-4932-4447-8dcf-1ecf88e0b350"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain<1.0.0,>=0.3.23 (from langchain-community)\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.22)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.49\n",
            "    Uninstalling langchain-core-0.3.49:\n",
            "      Successfully uninstalled langchain-core-0.3.49\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.7\n",
            "    Uninstalling langchain-text-splitters-0.3.7:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.22\n",
            "    Uninstalling langchain-0.3.22:\n",
            "      Successfully uninstalled langchain-0.3.22\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.51 langchain-text-splitters-0.3.8 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq # Install the langchain-groq package, which contains the ChatGroq class."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OQJ13PZJeYA",
        "outputId": "f714864f-8461-4cae-dc18-1220455c35f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.3.51)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.22.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.13.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.3.22)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.10.16)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.3.0)\n",
            "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: langchain-groq\n",
            "Successfully installed langchain-groq-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   GROQ_API_KEY = \"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\"\n",
        "   # Replace with your API key"
      ],
      "metadata": {
        "id": "WbAq1KskRGgg"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "# استخدام واجهة YouTubeTranscriptAPI لجلب الترجمة\n",
        "def get_transcript(video_id):\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "      # transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "\n",
        "    return transcript\n"
      ],
      "metadata": {
        "id": "OQEeT2FCAX8i"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# دمج النصوص بحيث يحتوي كل نص على 60 كلمة مع الحفاظ على التوقيت\n",
        "def merge_texts_to_60_words(transcript, max_words_per_text=90):\n",
        "    merged_texts = []\n",
        "    current_text = []\n",
        "    current_word_count = 0\n",
        "    current_start_time = None\n",
        "\n",
        "    for entry in transcript:\n",
        "        text = entry['text']\n",
        "        words = text.split()\n",
        "\n",
        "        for word in words:\n",
        "            if current_word_count == 0:\n",
        "                current_start_time = entry['start']  # تحديد وقت البدء لأول كلمة من النص\n",
        "            current_text.append(word)\n",
        "            current_word_count += 1\n",
        "\n",
        "            # إذا وصلنا إلى 60 كلمة، نقوم بإضافة النص المدمج\n",
        "            if current_word_count >= max_words_per_text:\n",
        "                merged_texts.append((current_start_time, \" \".join(current_text)))\n",
        "                current_text = []  # إعادة تعيين النص المدمج\n",
        "                current_word_count = 0\n",
        "\n",
        "    # إذا تبقى نص غير مكتمل يحتوي على أقل من 60 كلمة، نضيفه أيضًا\n",
        "    if current_text:\n",
        "        merged_texts.append((current_start_time, \" \".join(current_text)))\n",
        "\n",
        "    return merged_texts"
      ],
      "metadata": {
        "id": "DtPVsjKHAXit"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# تنسيق الترجمة مع التوقيت\n",
        "def format_transcript_with_time(transcript):\n",
        "    formatted_transcript = []\n",
        "\n",
        "    merged_texts = merge_texts_to_60_words(transcript)\n",
        "\n",
        "    for start_time, text in merged_texts:\n",
        "        # تحويل الوقت إلى صيغة (00:00:00)\n",
        "        minutes, seconds = divmod(start_time, 60)\n",
        "        hours, minutes = divmod(minutes, 60)\n",
        "        formatted_time = f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n",
        "\n",
        "        # إضافة التوقيت والنص\n",
        "        formatted_transcript.append(f\"{formatted_time}\\n{text}\")\n",
        "\n",
        "    return \"\\n\\n\".join(formatted_transcript)\n",
        "\n",
        "# جلب الترجمة من الفيديو\n",
        "video_id = '3u6QO3lKOtA'  # أدخل هنا الـ video ID\n",
        "transcript = get_transcript(video_id)\n",
        "\n",
        "# تنسيق الترجمة مع التوقيت\n",
        "formatted_transcript = format_transcript_with_time(transcript)\n",
        "# print(formatted_transcript)"
      ],
      "metadata": {
        "id": "RPIHv6KV_5vn"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "def get_text_chunks_from_transcript(\n",
        "    formatted_transcript: str,\n",
        "    video_id: str,\n",
        "    chunk_size: int = 1000,\n",
        "    chunk_overlap: int = 200\n",
        ") -> Tuple[List[str], List[Dict[str, str]]]:\n",
        "    \"\"\"\n",
        "    Split formatted transcript text (with timestamps) into chunks for embedding.\n",
        "\n",
        "    Args:\n",
        "        formatted_transcript: Transcript text with timestamps.\n",
        "        video_id: YouTube Video ID.\n",
        "        chunk_size: Maximum chunk size.\n",
        "        chunk_overlap: Overlap between chunks.\n",
        "\n",
        "    Returns:\n",
        "        chunks: List of text chunks.\n",
        "        metadata: List of dicts with video_id and chunk number.\n",
        "    \"\"\"\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len\n",
        "    )\n",
        "\n",
        "    chunks = text_splitter.split_text(formatted_transcript)\n",
        "\n",
        "    metadata = [\n",
        "        {\"video_id\": video_id, \"chunk\": i + 1}\n",
        "        for i in range(len(chunks))\n",
        "    ]\n",
        "\n",
        "    return chunks, metadata\n",
        "\n",
        "get_text_chunks= get_text_chunks_from_transcript(\n",
        "    formatted_transcript,\n",
        "    video_id,\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 200\n",
        ")\n",
        "# print(get_text_chunks)\n",
        "# print(metadata)  # Prints metadata for each chunk\n",
        "chunks, metadata = get_text_chunks_from_transcript(formatted_transcript, video_id)\n",
        "print(chunks)  # Prints the text chunks\n",
        "print(metadata)  # Prints metadata for each chunk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LhwJx6LAmyK",
        "outputId": "2398ffaa-fb5f-49f0-f670-de6d807fc68c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"00:00:00\\nO Abu Hazem, why do we hate death? You like the video, don't forget to click on the button Like and subscribe to the channel, oh Sheikh Meshari human when he enters the world, he enters it by one When he comes out of it, he comes out when he is ran in His grave is an individual and when he stands in the hands of his Lord He stands one, so he should mention this Lord, glory be to Him He says that to decorate what is between him\\n00:00:25\\nand between Even if a day comes to him, he will not come Looking is like the servant who kept an individual to His money is in response and dragged to him, but he comes with who His relationship with him is good and his ropes with him, and all of them It came on the day of resurrection, as our Lord said in Another place, and you have come to us as an individual as we created you The first time and you left what we have gave you\\n00:00:56\", '00:00:56\\nbehind your back We have made you money, supporters and servants And all of this left you behind your backs and what we see With you, your intercessors who were claiming They are partners in you, where are these people? Aslamo while they put in your graves, and they were walked and left And they succeeded you behind their backs, this truth should be If a woman pays attention to her and I do not like that not He succeeds him behind his back, so let him give him the\\n00:01:30\\nMessenger of God May God bless him and grant him peace A Muslim says Ibn Adam Mali Mali and is you oh Ibn Adam from Malik, except what I ate and I wore So I gave up and believed, God is the owner of this, except That is a heir that is not an owner, not an owner, but it is His money is the heir, you are one of these three What I wore it فابليت وما وما اكلته فادمت وا فنيته وما I gave it, and I kept\\n00:02:01', '00:02:01\\nme up, and therefore in the hadith Who delaying the one who seen Al -Tirmidhi when she gave charity عائشه رضي الله عنها بالشات كلها الا Her arm came to the Messenger of God, may God bless him and grant him peace So she asked her and she said all of her arm He said, but it remained all except for its arm, so this is What a person should remember and his money He who loves him, let him serve him to his house in front of him You\\n00:02:30\\nknow, Sheikh Mashari, that each of us has Darren, this house, which he lives in this house And the other house that it prepares upon the transfer You had something that you would have loved, so he came from it, so no Fear all where you are backward, do not let it all in the place What you manage From him in the place you come and therefore he said One of them and who is the concern of the world To collect it, I will one day be a\\n00:02:56', '00:02:56\\nhate, not a house For one after death, it is inhabited except that it was before Death builds it, so he built it well And if it was built by human beings, he would be able to do it Because it comes at least, he finds no finding A ruin in front of him, he finds his homes in his hands History and biographies mention that Suleiman bin Abd al -Malik al -Khalifa, the famous Umayyad, my template Hazem Al -Tamar Abu Hazem Al -Tamar This is one City scientists\\n00:03:27\\nare one of the preachers Zahid said by Solomon, O Abu Hazim, we do not mind The string of death, so he said to him, O Commander of the Believers, because you are You ruined the hereafter and the world is old, so you hate Exit from urbanism to ruin, God is great This is my logic Urban and resident is a juvenile and goes By ruin against the nature of things, he said because you are خربتم الدنيا عمرتم الدنيا وخربتم الاخره You hate going out of the urban\\n00:04:05', '00:04:05\\nThe ruin said to him, O Abu Hazim, if only my hair We have with God tomorrow, and he said, O Commander of the Faithful Show your work on the book of God, you know, you know What do you have with God? He said where do I find it in a book God said in his saying that the righteous is in Naim and that The ungodly has a hell, and Abd al -Mul said, and he said Suleiman Fayne, may God have mercy on him Abu Hazim said\\n00:04:30\\nclose to The benefactors of God are the greatest close to the benefactors This case, Sheikh مشاري كانت حاضره عند The successful this perception and you have come to us Farada and all of them came on the day of resurrection On the individual and the successful people were keen to present Things in front of them and he was in his actions World And its fluctuations mention the owners of dates that Suleiman Bin Abd al -Malik, this went out one day in a crowd with His companions And\\n00:05:12', '00:05:12\\nhis blood was close His cousin Omar bin Abdul Dear, of course, these princes will go out and repel Walms And Siboni, who chose him for ointments Their hands serve them in heavy and their tents needed To him in Their stay Omar bin Abdul Aziz did not provide anything Resurrection One of the important people settled, and when they reached the position of T. And their groom and each of these princes was He presented in front of him things, so every went to his tent that I was\\n00:05:52\\ninstalled For him, when he was rest Suleiman remembers Omar bin Abdul Aziz and learned that he Not Something said Ask him, so they went looking for it and found it in the shadow A thorough tree crying this is from the strangeness of this man This is one of the strange things with Omar Abdel Aziz, may God bless him God On him, they told Solomon that it is such and such an elephant u He cried, pray to him, and when he came to him, Malik said, O\\n00:06:22', '00:06:22\\nAba Abdul Malik And he said, O Commander of the Believers, I remembered myself, I remembered My current one is this this is what happened I measure it on the matter of the last, he said I remembered myself I fled, who presented something and did not give anything I did not find anything of God, the lesson from the world This is in a very beautiful salvation Omar bin Abdul Aziz They presented something when they came and found what They presented it and did not reach this staying\\n00:06:58\\nfor the stay In Khurram, they found an erected treachery and found eating They found drinking well, so well, so in The last one says that I did not offer anything, but I did not intensify Something and this coming as the resurrection means It comes when this coming begins even in the grave I mean, the watch of man, I mean, of course, this is You know, Sheikh Bishary, that this You come to see people, I can comment on people People and have mercy on people and kindness\\n00:07:28', '00:07:28\\npeople People And who is hungry to satiate and who stays up to sleep And who narrows himself to expand you The parents are in their hands, they put Their child in the pits and go to any A scene in unique For people, if people are preaching, this is a father Nawas had a lot of preaching to him always Aba Nawas preaches, of course, Maarouf Abu Nawas, then died That owner and Abu Nawas attended his funeral and stood on His grave, when he saw, put in his\\n00:08:08\\ngrave an individual who said to him Today you are silent or preached from you A preaching is more informed of the sermons that I have always been Him your silence today in the sermon is more reported to me Your pronunciation is a good Sheikh, how do a person reconcile a supplication The Prophet, may God bless him and grant him peace, may God hold me accountable Account Yusra and the hadith from the discussion of the account is fresh, sweet Our Lord, Glory be to Him, if he\\n00:08:39', '00:08:39\\nwants to have mercy on his servant, according to Him An easy account is not that The discussion if the discussion comes and consider Details, as the Messenger of God, may God bless And peace be upon him from the inscription of the account is fresh or inserted Paradise without calculation or the torment of this happiness Paradise enters it without an account or its predecessor is a torment, we ask God is to be among them, O Lord, but this is all He does not pay that he will\\n00:09:04\\nsee him on the day of resurrection, oh Sheikh Meshari is one of the people in his sleep does not sleep A individual who does not know the unilateralness of his sleep in his stay On his night on his travel on his trips in always Surrounded by his companions, supporters, agents, or Bashia there and you have come to us and this should be To guide people until they take a link between us He cuts yes, and he arrived, may God meet all His companions, every friendship is\\n00:09:43', '00:09:43\\nbased on non -piety, it is To his enmity as our Lord said and then on the day of resurrection Atone for each other and curse each other and said Rather, you took without God, whom you are affectionate Among you in the lower life is between you The lower life is readers, then the day of resurrection is cursed Some of you disbelieve each other and curse each other Some either the piety is not interrupted and their connection God evacuates that day for each other, but an enemy\\n00:10:16', '00:10:16\\nThe righteous, this is a Sheikh indicating that A person is unique to himself, empty himself and hold accountable Himself before the account, well, hold yourselves before To be held accountable, remember your condition in the individual God, who makes you supporters, do not leave They curse him, do not become, and do not become enemies for you And if they are the closest relative, he should not think He thought that this boy, this boy, and this father And this brother, a day one escapes from his brother and\\n00:10:47', \"00:10:47\\nmother وابيه وصاحبته وبنيه لكل امرئ منهم يومئذ So God will sing the greatest Muslim Glory be to God I mean, from the blessings of God Almighty, he must feel Such a matter because he believes in resurrection And the publication is true, and this faith is the pregnant woman He has to do good and patience for its volatility The world, and this is what the Messenger of God, may God’s prayers May God bless him and grant him peace The whole believer has good and not for that\\n00:11:25\\nand not that Except for the believer if he suffers Good thanks, it was better for him if he had a shield Patience was good for him that he sees all of this His Lord will reward him and benefit him when he is between him His hands if you like the video, don't forget to click Like button and subscribe to the channel\"]\n",
            "[{'video_id': '3u6QO3lKOtA', 'chunk': 1}, {'video_id': '3u6QO3lKOtA', 'chunk': 2}, {'video_id': '3u6QO3lKOtA', 'chunk': 3}, {'video_id': '3u6QO3lKOtA', 'chunk': 4}, {'video_id': '3u6QO3lKOtA', 'chunk': 5}, {'video_id': '3u6QO3lKOtA', 'chunk': 6}, {'video_id': '3u6QO3lKOtA', 'chunk': 7}, {'video_id': '3u6QO3lKOtA', 'chunk': 8}, {'video_id': '3u6QO3lKOtA', 'chunk': 9}, {'video_id': '3u6QO3lKOtA', 'chunk': 10}, {'video_id': '3u6QO3lKOtA', 'chunk': 11}, {'video_id': '3u6QO3lKOtA', 'chunk': 12}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Union\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "def get_vectorstore(\n",
        "    text_chunks: List[str],\n",
        "    metadata: List[Dict[str, str]],\n",
        "    embedding_model: Union[str, HuggingFaceEmbeddings],\n",
        "    save_path: str = None\n",
        ") -> FAISS:\n",
        "    \"\"\"\n",
        "    Create a FAISS vectorstore from text chunks & metadata.\n",
        "\n",
        "    Args:\n",
        "        text_chunks: List of text chunks.\n",
        "        metadata: Corresponding metadata for each chunk.\n",
        "        embedding_model: Model name (str) or HuggingFaceEmbeddings object.\n",
        "        save_path: Optional path to persist FAISS vectorstore.\n",
        "\n",
        "    Returns:\n",
        "        FAISS Vectorstore object.\n",
        "    \"\"\"\n",
        "\n",
        "    embeddings = embedding_model if isinstance(embedding_model, HuggingFaceEmbeddings) else HuggingFaceEmbeddings(model_name=embedding_model)\n",
        "\n",
        "    vectorstore = FAISS.from_texts(\n",
        "        texts=text_chunks,\n",
        "        embedding=embeddings,\n",
        "        metadatas=metadata\n",
        "    )\n",
        "\n",
        "    if save_path:\n",
        "        vectorstore.save_local(save_path)\n",
        "\n",
        "    return vectorstore\n",
        "vectorstore = get_vectorstore(chunks, metadata, embedding_model=HuggingFaceEmbeddings(), save_path=\"faiss_index\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M7H08kYHoWu",
        "outputId": "130a2b5e-cd5f-46ea-dc09-7b2dcc743814"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-97-1613355cc9be>:36: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  vectorstore = get_vectorstore(chunks, metadata, embedding_model=HuggingFaceEmbeddings(), save_path=\"faiss_index\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def get_conversation_chain(vectorstore: FAISS, llm_model: str = \"llama-3.3-70b-specdec\"):\n",
        "    \"\"\"\n",
        "    Initialize a conversational retrieval chain with LLM and vectorstore.\n",
        "\n",
        "    Args:\n",
        "        vectorstore: FAISS vectorstore.\n",
        "        llm_model: Name of LLM model to use (OpenAI or Groq).\n",
        "\n",
        "    Returns:\n",
        "        ConversationalRetrievalChain object.\n",
        "    \"\"\"\n",
        "    groq_api_key=\"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\"\n",
        "    # Dynamically choose LLM\n",
        "    if llm_model.startswith(\"llama\"):\n",
        "        llm = ChatGroq(model=llm_model,groq_api_key=groq_api_key)\n",
        "\n",
        "    # else:\n",
        "    #     llm = ChatOpenAI(model=llm_model)\n",
        "\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history',\n",
        "        return_messages=True\n",
        "    )\n",
        "\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"question\", \"context\"],\n",
        "        template=\"\"\"\n",
        "You are an intelligent assistant.\n",
        "\n",
        "Use ONLY the context provided to answer the question.\n",
        "\n",
        "If the answer is not in the context, say \"Sorry, I don't know.\"\n",
        "\n",
        "Answer in a concise and clear way. Provide source when possible.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer (with source if available):\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        memory=memory,\n",
        "        combine_docs_chain_kwargs={\"prompt\": prompt_template},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "    return chain\n",
        "\n"
      ],
      "metadata": {
        "id": "kslBQm1GJFfZ"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def get_conversation_chain(vectorstore: FAISS, llm_model: str = \"llama-3.3-70b-specdec\"):\n",
        "    \"\"\"\n",
        "    Initialize a conversational retrieval chain with LLM and vectorstore.\n",
        "\n",
        "    Args:\n",
        "        vectorstore: FAISS vectorstore.\n",
        "        llm_model: Name of LLM model to use (OpenAI or Groq).\n",
        "\n",
        "    Returns:\n",
        "        ConversationalRetrievalChain object.\n",
        "    \"\"\"\n",
        "    groq_api_key=\"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\"\n",
        "    # Dynamically choose LLM\n",
        "    if llm_model.startswith(\"llama\"):\n",
        "        llm = ChatGroq(model=llm_model,groq_api_key=groq_api_key)\n",
        "\n",
        "    # else:\n",
        "    #     llm = ChatOpenAI(model=llm_model)\n",
        "\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history',\n",
        "        return_messages=True,\n",
        "        # Explicitly setting the output_key\n",
        "        output_key='answer'\n",
        "    )\n",
        "\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"question\", \"context\"],\n",
        "        template=\"\"\"\n",
        "You are an intelligent assistant.\n",
        "\n",
        "Use ONLY the context provided to answer the question.\n",
        "\n",
        "If the answer is not in the context, say \"Sorry, I don't know.\"\n",
        "\n",
        "Answer in a concise and clear way.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        memory=memory,\n",
        "        combine_docs_chain_kwargs={\"prompt\": prompt_template},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "    return chain"
      ],
      "metadata": {
        "id": "xs_O753ITLOI"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chain = get_conversation_chain(vectorstore, llm_model=\"llama-3.3-70b-specdec\")\n"
      ],
      "metadata": {
        "id": "2Ld9I5xVKiyq"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After getting the response from the conversation chain\n",
        "response = conversation_chain({\n",
        "    'question': 'ما هو الموضوع الرئيسي للفيديو؟'\n",
        "})\n",
        "\n",
        "# Extract the answer\n",
        "answer = response['answer']\n",
        "print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHbqZ6LEUMsK",
        "outputId": "1816dbf5-3090-4f56-99b7-a2b9f647e854"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "الموضوع الرئيسي للفيديو هو الحديث عن الموت واليوم الآخر والحث على التذكر والتقرب إلى الله.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After getting the response from the conversation chain\n",
        "response = conversation_chain({\n",
        "    'question': 'أعطني بعض الأسئلة والأجوبة'\n",
        "\n",
        "})\n",
        "\n",
        "# Extract the answer\n",
        "answer = response['answer']\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L94dKN9ZUknd",
        "outputId": "b5117f26-7112-49e5-b921-1f480323a13d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "الفيديو يحتوي على تعاليم دينية ويتناول مواضيع متعلقة بالحياة الآخرة والخلود. بعض الأسئلة والأجوبة التي يمكن أن تناقشها حول الفيديو تشمل:\n",
            "\n",
            "- ما هو مفهوم الجنة والنار في الإسلام؟\n",
            "- كيف يمكننا تحقيق الفوز في الحياة الآخرة؟\n",
            "- ما هي الأعمال الصالحة التي يمكننا القيام بها لتصل إلى الجنة؟\n",
            "- كيف يمكننا تجنب الأعمال السيئة التي قد تؤدي إلى النار؟\n",
            "- ما هي دورة الحساب في يوم القيامة؟\n",
            "- كيف يمكننا الاستعداد للقاء الله في الحياة الآخرة؟\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After getting the response from the conversation chain\n",
        "response = conversation_chain({\n",
        "    'question': ' اجبني على هده الاسئلة  '\n",
        "\n",
        "})\n",
        "\n",
        "# Extract the answer\n",
        "answer = response['answer']\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwR3v6GWazdY",
        "outputId": "4b3d6b01-0399-44b4-ab0a-d70b52d992cc"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "إجابات على الأسئلة:\n",
            "- مفهوم الجنة والنار في الإسلام: الجنة هي مكان النعيم والسرور للأذين أطاعوا الله، والنار هي مكان العذاب للأذين عصوا الله.\n",
            "- تحقيق الفوز في الحياة الآخرة: يمكننا تحقيق الفوز من خلال الأعمال الصالحة والطاعة لله.\n",
            "- الأعمال الصالحة: يمكننا القيام بالصلوات، والصدقة، والصيام، والحج، والقراءة للقرآن.\n",
            "- تجنب الأعمال السيئة: يمكننا تجنب الأعمال السيئة من خلال الابتعاد عن الشهوات والرذائل.\n",
            "- دورة الحساب في يوم القيامة: الحساب هو عملية محاسبة الأفراد على أعمالهم في الحياة الدنيا.\n",
            "- الاستعداد للقاء الله: يمكننا الاستعداد من خلال التوبة، والتقرب إلى الله، والقيام بالأعمال الصالحة.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4bBZETt9bJgr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}